{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MOT metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import motmetrics as mm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:10:33.283086600Z",
     "start_time": "2023-07-20T10:10:32.753777600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name|Description\r\n",
      ":---|:---\r\n",
      "num_frames|Total number of frames.\r\n",
      "obj_frequencies|Total number of occurrences of individual objects over all frames.\r\n",
      "pred_frequencies|Total number of occurrences of individual predictions over all frames.\r\n",
      "num_matches|Total number matches.\r\n",
      "num_switches|Total number of track switches.\r\n",
      "num_transfer|Total number of track transfer.\r\n",
      "num_ascend|Total number of track ascend.\r\n",
      "num_migrate|Total number of track migrate.\r\n",
      "num_false_positives|Total number of false positives (false-alarms).\r\n",
      "num_misses|Total number of misses.\r\n",
      "num_detections|Total number of detected objects including matches and switches.\r\n",
      "num_objects|Total number of unique object appearances over all frames.\r\n",
      "num_predictions|Total number of unique prediction appearances over all frames.\r\n",
      "num_unique_objects|Total number of unique object ids encountered.\r\n",
      "track_ratios|Ratio of assigned to total appearance count per unique object id.\r\n",
      "mostly_tracked|Number of objects tracked for at least 80 percent of lifespan.\r\n",
      "partially_tracked|Number of objects tracked between 20 and 80 percent of lifespan.\r\n",
      "mostly_lost|Number of objects tracked less than 20 percent of lifespan.\r\n",
      "num_fragmentations|Total number of switches from tracked to not tracked.\r\n",
      "motp|Multiple object tracker precision.\r\n",
      "mota|Multiple object tracker accuracy.\r\n",
      "precision|Number of detected objects over sum of detected and false positives.\r\n",
      "recall|Number of detections over number of objects.\r\n",
      "id_global_assignment|ID measures: Global min-cost assignment for ID measures.\r\n",
      "idfp|ID measures: Number of false positive matches after global min-cost matching.\r\n",
      "idfn|ID measures: Number of false negatives matches after global min-cost matching.\r\n",
      "idtp|ID measures: Number of true positives matches after global min-cost matching.\r\n",
      "idp|ID measures: global min-cost precision.\r\n",
      "idr|ID measures: global min-cost recall.\r\n",
      "idf1|ID measures: global min-cost F1 score.\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all default metrics\n",
    "mh = mm.metrics.create()\n",
    "print(mh.list_metrics_markdown())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:10:33.835600600Z",
     "start_time": "2023-07-20T10:10:33.804337300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate MOT metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions to compute motchallenge metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def compare_dataframes(gts, ts):\n",
    "    accs = []\n",
    "    names = []\n",
    "    for k, tsacc in ts.items():\n",
    "        if k in gts:\n",
    "            logging.info('Comparing {}...'.format(k))\n",
    "            accs.append(mm.utils.compare_to_groundtruth(gts[k], tsacc, 'iou', distth=0.5))\n",
    "            names.append(k)\n",
    "        else:\n",
    "            logging.warning('No ground truth for {}, skipping.'.format(k))\n",
    "\n",
    "    return accs, names\n",
    "\n",
    "\n",
    "def compute_motmetrics(groundtruths, tests, score_threshold, fmt='mot15-2D'):\n",
    "\n",
    "    gtfiles = glob.glob(os.path.join(groundtruths, '*/gt/gt.txt'))\n",
    "    print('gt_files', gtfiles)\n",
    "    tsfiles = [f for f in glob.glob(os.path.join(tests, '*.txt')) if not os.path.basename(f).startswith('eval')]\n",
    "\n",
    "    print('Found {} groundtruths and {} test files.'.format(len(gtfiles), len(tsfiles)))\n",
    "    print('Available LAP solvers {}'.format(mm.lap.available_solvers))\n",
    "    print('Default LAP solver \\'{}\\''.format(mm.lap.default_solver))\n",
    "    print('Loading files.')\n",
    "\n",
    "    gt = OrderedDict([(Path(f).parts[-3], mm.io.loadtxt(f, fmt=fmt, min_confidence=1)) for f in gtfiles])\n",
    "    ts = OrderedDict(\n",
    "        [(os.path.splitext(Path(f).parts[-1])[0], mm.io.loadtxt(f, fmt=fmt, min_confidence=score_threshold))\n",
    "         for f in tsfiles])\n",
    "    #     ts = gt\n",
    "\n",
    "    mh = mm.metrics.create()\n",
    "    accs, names = compare_dataframes(gt, ts)\n",
    "\n",
    "    logging.info('Running metrics')\n",
    "    metrics = ['recall', 'precision', 'num_unique_objects', 'mostly_tracked',\n",
    "               'partially_tracked', 'mostly_lost', 'num_false_positives', 'num_misses',\n",
    "               'num_switches', 'num_fragmentations', 'mota', 'motp', 'idf1', 'num_objects']\n",
    "    summary = mh.compute_many(accs, names=names, metrics=metrics, generate_overall=True)\n",
    "    div_dict = {\n",
    "        'num_objects': ['num_false_positives', 'num_misses', 'num_switches', 'num_fragmentations'],\n",
    "        'num_unique_objects': ['mostly_tracked', 'partially_tracked', 'mostly_lost']}\n",
    "    for divisor in div_dict:\n",
    "        for divided in div_dict[divisor]:\n",
    "            summary[divided] = (summary[divided] / summary[divisor])\n",
    "    fmt = mh.formatters\n",
    "    change_fmt_list = ['num_false_positives', 'num_misses', 'num_switches', 'num_fragmentations', 'mostly_tracked',\n",
    "                       'partially_tracked', 'mostly_lost']\n",
    "    for k in change_fmt_list:\n",
    "        fmt[k] = fmt['mota']\n",
    "    print(mm.io.render_summary(summary, formatters=fmt, namemap=mm.io.motchallenge_metric_names))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:53:13.369465400Z",
     "start_time": "2023-07-20T10:53:13.339848900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate metrics for DeepSort MOT20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GT - directory with ground truth sequences.\n",
    "DeepSort_predictions - directory with DeepSort predictions (*.txt files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_files ['GT\\\\MOT20-01\\\\gt\\\\gt.txt', 'GT\\\\MOT20-02\\\\gt\\\\gt.txt', 'GT\\\\MOT20-03\\\\gt\\\\gt.txt', 'GT\\\\MOT20-05\\\\gt\\\\gt.txt']\n",
      "Found 4 groundtruths and 4 test files.\n",
      "Available LAP solvers ['scipy']\n",
      "Default LAP solver 'scipy'\n",
      "Loading files.\n",
      "          Rcll  Prcn   GT   MT    PT    ML   FP    FN  IDs   FM  MOTA  MOTP  IDF1 num_objects\n",
      "MOT20-01 20.1% 89.5%   74 5.4% 29.7% 64.9% 2.4% 79.9% 0.1% 0.6% 17.7% 0.075 28.2%       19870\n",
      "MOT20-02 22.0% 89.0%  270 3.7% 38.5% 57.8% 2.7% 78.0% 0.1% 0.6% 19.2% 0.074 28.0%      154742\n",
      "MOT20-03  0.5% 77.7%  702 0.0%  0.4% 99.6% 0.2% 99.5% 0.0% 0.1%  0.4% 0.092  0.8%      313658\n",
      "MOT20-05  0.4% 76.1% 1169 0.0%  0.2% 99.8% 0.1% 99.6% 0.0% 0.0%  0.3% 0.102  0.7%      646344\n",
      "OVERALL   3.8% 87.6% 2215 0.6%  5.9% 93.5% 0.5% 96.2% 0.0% 0.1%  3.2% 0.077  5.8%     1134614\n"
     ]
    }
   ],
   "source": [
    "compute_motmetrics(groundtruths=\"GT\", tests=\"DeepSort_Predictions\", score_threshold=0.5, fmt='mot15-2D')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:53:38.408187300Z",
     "start_time": "2023-07-20T10:53:14.814485700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculte metrics for SORT MOT20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sort/output - directory with SORT predictions (*.txt files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_files ['GT\\\\MOT20-01\\\\gt\\\\gt.txt', 'GT\\\\MOT20-02\\\\gt\\\\gt.txt', 'GT\\\\MOT20-03\\\\gt\\\\gt.txt', 'GT\\\\MOT20-05\\\\gt\\\\gt.txt']\n",
      "Found 4 groundtruths and 4 test files.\n",
      "Available LAP solvers ['scipy']\n",
      "Default LAP solver 'scipy'\n",
      "Loading files.\n",
      "          Rcll  Prcn   GT    MT    PT    ML   FP    FN  IDs   FM  MOTA  MOTP  IDF1 num_objects\n",
      "MOT20-01 54.1% 90.6%   74 23.0% 52.7% 24.3% 5.6% 45.9% 0.9% 1.2% 47.7% 0.089 48.1%       19870\n",
      "MOT20-02 50.2% 91.5%  270 21.5% 61.1% 17.4% 4.6% 49.8% 0.7% 1.0% 44.8% 0.081 37.5%      154742\n",
      "MOT20-03 45.8% 94.1%  702 10.3% 59.7% 30.1% 2.9% 54.2% 1.3% 2.1% 41.6% 0.137 35.1%      313658\n",
      "MOT20-05 47.2% 90.7% 1169 12.2% 60.7% 27.1% 4.8% 52.8% 1.2% 1.9% 41.2% 0.127 30.7%      646344\n",
      "OVERALL  47.3% 91.7% 2215 13.1% 60.1% 26.8% 4.3% 52.7% 1.1% 1.8% 41.9% 0.122 33.1%     1134614\n"
     ]
    }
   ],
   "source": [
    "compute_motmetrics(groundtruths=\"GT\", tests=\"sort/output\", score_threshold=0.5, fmt='mot15-2D')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:55:20.199776300Z",
     "start_time": "2023-07-20T10:53:43.056691500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With SORT we have much better results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating metrics for IOU-tracker MOT20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "iou-tracker/output contains predictions in *.txt format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_files ['GT\\\\MOT20-01\\\\gt\\\\gt.txt', 'GT\\\\MOT20-02\\\\gt\\\\gt.txt', 'GT\\\\MOT20-03\\\\gt\\\\gt.txt', 'GT\\\\MOT20-05\\\\gt\\\\gt.txt']\n",
      "Found 4 groundtruths and 4 test files.\n",
      "Available LAP solvers ['scipy']\n",
      "Default LAP solver 'scipy'\n",
      "Loading files.\n",
      "          Rcll  Prcn   GT   MT    PT    ML   FP    FN  IDs   FM  MOTA  MOTP  IDF1 num_objects\n",
      "MOT20-01 17.8% 90.2%   74 5.4% 23.0% 71.6% 1.9% 82.2% 0.4% 0.4% 15.5% 0.059 19.7%       19870\n",
      "MOT20-02 20.3% 89.3%  270 3.0% 37.0% 60.0% 2.4% 79.7% 0.4% 0.4% 17.4% 0.059 20.4%      154742\n",
      "MOT20-03  0.3% 74.8%  702 0.0%  0.3% 99.7% 0.1% 99.7% 0.0% 0.0%  0.2% 0.077  0.2%      313658\n",
      "MOT20-05  0.3% 73.5% 1169 0.0%  0.2% 99.8% 0.1% 99.7% 0.0% 0.0%  0.2% 0.075  0.4%      646344\n",
      "OVERALL   3.3% 88.0% 2215 0.5%  5.5% 94.0% 0.5% 96.7% 0.1% 0.1%  2.8% 0.060  3.9%     1134614\n"
     ]
    }
   ],
   "source": [
    "compute_motmetrics(groundtruths=\"GT\", tests=\"iou-tracker/output\", score_threshold=0.5, fmt='mot15-2D')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:56:40.732157900Z",
     "start_time": "2023-07-20T10:56:16.303116900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SORT algorithm appeared to be the best among others, then goes DeepSort and then IOU-tracker."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
